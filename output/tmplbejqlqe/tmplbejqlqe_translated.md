# 探索用于对象检测的纯视觉Transformer骨干网络

李阳浩、毛翰子、Ross Girshick $ ^{\dagger} $、何凯明 $ ^{\dagger} $

Facebook AI Research

## 摘要
我们探索了纯视觉Transformer（ViT）作为对象检测的骨干网络。这种设计使得原始的ViT架构可以直接进行微调以适应对象检测任务，而无需为预训练重新设计分层架构。通过最小的微调调整，我们的纯骨干检测器能够取得有竞争力的结果。令人惊讶的是，我们观察到：（i）仅从单尺度特征图构建一个简单的特征金字塔（无需常见的FPN设计）就足够了；（ii）使用窗口注意力（无需移动）并结合少量的跨窗口传播块也足够了。通过将纯ViT骨干网络预训练为掩码自编码器（MAE），我们的检测器ViTDet能够与之前基于分层骨干的网络竞争，在COCO数据集上仅使用ImageNet-1K预训练即可达到61.3 AP $ ^{box} $ 的成绩。我们希望我们的研究能够引起人们对纯骨干检测器研究的关注。ViTDet的代码是可用的。$ ^{1} $ 

## 1 引言
现代对象检测器通常由一个与检测任务无关的骨干特征提取器和一组结合了特定检测知识的neck和head组成。neck/head中的常见组件可能包括感兴趣区域（RoI）操作 $ [26,20,25] $、区域提议网络（RPN）或锚点 $ [48] $、特征金字塔网络（FPN） $ [37] $ 等。如果将特定于任务的neck/head的设计与骨干的设计分离，它们可以并行发展。从经验上看，对象检测研究从通用骨干 $ [30,49,50,27] $ 和特定于检测的模块的独立探索中受益匪浅。长期以来，由于卷积网络（ConvNet） $ [32] $ 的实际设计，这些骨干都是多尺度的、分层的，这极大地影响了在多个尺度上检测对象的设计（例如，FPN）。

在过去的一年中，视觉Transformer（ViT） $ [14] $ 已经成为视觉识别领域的强大骨干。与典型的ConvNet不同，原始的ViT是一个纯的、非分层的架构，它在整个过程中保持单一尺度特征图。其“极简主义”的追求在应用于对象检测时遇到了挑战——例如，我们如何使用上游预训练的纯骨干来处理多尺度对象？纯ViT是否太不高效，无法用于高分辨率的检测图像？一种解决方案是重新引入分层设计到骨干中。例如，Swin Transformers $ [42] $ 及相关工作 $ [55,17,34,29] $ 就采用了这种解决方案，并取得了成功的结果。

在这项工作中，我们探索了另一种方向：我们研究仅使用纯的、非分层骨干的对象检测器。 $ ^{2} $ 如果这一方向成功，它将使得使用原始的ViT骨干进行对象检测成为可能；这将使预训练设计与微调需求解耦，保持上游与下游任务的独立性，就像基于ConvNet的研究那样。这一方向也部分遵循了ViT的哲学，即“减少归纳偏见” $ [14] $，以追求通用特征。由于非局部自注意力计算 $ [54] $ 可以学习平移等变的特征 $ [14] $，它们也可能从某种形式的监督或自监督预训练中学习尺度等变特征。

在我们的研究中，我们并不旨在开发新组件；相反，我们进行了最小的调整，这些调整足以克服上述挑战。特别是，我们的检测器仅从纯ViT骨干的最后一个特征图构建了一个简单的特征金字塔（图1）。这放弃了FPN设计 [37]，并且不需要分层骨干。为了从高分辨率图像中高效提取特征，我们的检测器使用了简单的非重叠窗口注意力（无需“移动”，与 [42] 不同）。使用少量的跨窗口块（例如，4个），这些块可以是全局注意力 [54] 或卷积，来传播信息。这些调整仅在微调期间进行，并不改变预训练。

我们的简单设计取得了令人惊讶的结果。我们发现，在纯ViT骨干的情况下，FPN设计是不必要的，其好处可以通过从大步长（16）的单尺度图构建的简单金字塔有效获得。我们还发现，只要信息能够在少数层中良好地跨窗口传播，窗口注意力就足够了。

更令人惊讶的是，在某些情况下，我们的纯骨干检测器ViTDet可以与领先的分层骨干检测器竞争（例如，Swin [42]、MViT [17,34]）。通过掩码自编码器（MAE）[24] 预训练，我们的纯骨干检测器能够在没有标签的情况下，仅使用ImageNet-1K预训练，在COCO数据集上达到61.3 AP $ ^{box} $ 的成绩。我们还在长尾LVIS检测数据集 [23] 上展示了有竞争力的结果。虽然这些强劲的结果可能在一定程度上归功于MAE预训练的有效性，但我们的研究表明，纯骨干检测器是有前途的，挑战了分层骨干在对象检测中的主导地位。

除了这些结果，我们的方法论保持了将特定于检测器的设计与与任务无关的骨干分离的哲学。这种哲学与重新设计Transformer骨干以支持多尺度层次结构的趋势相反 [42,55,17,29]。在我们的案例中，特定于检测的先验知识仅在微调期间引入，无需在预训练阶段预先定制骨干设计。这使得我们的检测器能够与ViT的各种发展保持兼容，这些发展不必然受到层次结构的限制，例如，块设计 [52,53]、自监督学习 [2,24] 和缩放 [57]。我们希望我们的研究能够激发未来关于纯骨干对象检测的研究。 $ ^{3} $ 

## 2 相关工作
对象检测器骨干。R-CNN [21] 的工作开创了对象检测和许多其他视觉任务的预训练+微调范式：一个通用的、与任务无关的骨干先使用监督或自监督训练进行预训练，其结构随后被修改和适应下游任务。计算机视觉中的主导骨干一直是各种形式的ConvNets [32]，例如 [30,49,50,27]。

早期的神经网络检测器，例如 [26,20,48,47]，最初是基于单尺度特征图的。虽然它们使用的ConvNet骨干默认是分层的，但原则上它们可以应用于任何纯骨架。SSD [40] 是最早利用ConvNet骨干的分层特性的工作之一（例如，VGG网络的最后两个阶段 [49]）。FPN [37] 通过使用分层骨干的所有阶段，并通过侧向和自上而下的连接，进一步推动了这一方向。FPN设计在对象检测方法中得到了广泛应用。最近，包括Trident Networks [33] 和YOLOF [7] 在内的工作重新审视了单尺度特征图，但与我们的工作不同，他们专注于从分层骨干中获取的单尺度特征。

ViT [14] 是图像分类的强大替代方案。原始的ViT是一个纯的、非分层的架构。已经提出了各种分层Transformer，例如Swin [42]、MViT [17,34]、PVT [55] 和PiT [29]。这些方法继承了一些ConvNet的设计，包括分层结构和平移等变的先验（例如，卷积、池化、滑动窗口）。因此，用这些骨干替换ConvNet进行对象检测相对直接。

纯骨干检测器。ViT的成功启发人们推动了纯骨干在对象检测领域的探索。最近，UViT [9] 被提出作为一个用于对象检测的单尺度Transformer。UViT研究了纯ViT骨干的网络宽度、深度和输入分辨率在对象检测指标下的表现。提出了一种渐进的窗口注意力策略来处理高分辨率输入。与在预训练期间修改架构的UViT不同，我们的研究专注于原始的ViT架构，没有预先指定用于检测。通过保持骨干的与任务无关的性质，我们的方法支持了各种可用的ViT骨干及其未来的改进。我们的方法将骨干设计与检测任务解耦，这是追求纯骨干的关键动机。

UViT使用单尺度特征图作为检测器的头部，而我们的方法在单尺度骨干上构建了一个简单的分层金字塔。在我们的研究中，整个检测器必须是单尺度的并不是一个必要限制。注意，完整的UViT检测器也有几种多尺度先验形式（例如，RPN [48] 和RoIAlign [25]），因为它基于Cascade Mask R-CNN [4]。在我们的研究中，我们专注于利用预训练的纯骨干，我们不限制检测器的neck/head设计。

对象检测方法。对象检测是一个蓬勃发展的研究领域，它采用了具有不同属性的方法学——例如，两阶段 [21,26,20,48] 与单阶段 [47,40,38]、基于锚点的 [48] 与无锚点的 [31,15,51]、基于区域的 [21,26,20,48] 与基于查询的（DETR）[5]。对不同方法学的研究不断推进了对对象检测问题的理解。我们的研究表明，“纯阵营与分层阵营”骨干的话题值得探索，并可能带来新的见解。

## 3 方法
我们的目标是去除骨干的分层限制，并能够探索纯骨干的对象检测。为此，我们希望在微调期间对纯骨干进行最小的修改，以适应对象检测任务。在这些调整之后，原则上可以应用任何检测器头部，我们选择使用Mask R-CNN [25] 及其扩展。我们不旨在开发新组件；相反，我们专注于在我们的探索中可以得出哪些新的见解。

简单的特征金字塔。FPN [37] 是构建用于对象检测的网络内金字塔的常见方法。如果骨干是分层的，FPN的动机是将早期阶段的更高分辨率特征与后期阶段的更强特征结合起来。这在FPN中通过自上而下的和侧向连接实现 [37] （图1左侧）。

（a）FPN，4个阶段

（b）FPN的最后一个图层

（c）简单的特征金字塔

（d）图2：在纯骨干上构建特征金字塔。（a）类似FPN：为了模仿分层骨干，将纯骨干人为地划分为多个阶段。（b）类似FPN，但只使用最后一个特征图，不进行阶段划分。（c）我们的简单特征金字塔，不使用FPN。在这三种情况下，每当尺度变化时都使用步长卷积/反卷积。

如果骨干是非分层的，FPN的动机就失去了基础，因为骨干中的所有特征图都具有相同的分辨率。在我们的场景中，我们简单地使用骨干的最后一个特征图，该特征图应该具有最强的特征。在这个图上，我们并行应用一组卷积或反卷积来生成多尺度特征图。具体来说，使用ViT的默认特征图，其尺度为 $ \frac{1}{16} $（步长 = 16 [14]），我们使用步长为 $ \{2, 1, \frac{1}{2}, \frac{1}{4}\} $ 的卷积来生成尺度为 $ \{\frac{1}{32}, \frac{1}{16}, \frac{1}{8}, \frac{1}{4}\} $ 的特征图，其中分数步长表示反卷积。我们将其称为“简单特征金字塔”（图1右侧）。

从单张图构建多尺度特征图的策略与SSD [40] 的策略相关。然而，我们的场景涉及从深度低分辨率特征图上进行上采样，与 [40] 不同，后者利用的是较浅的特征图。在分层骨干中，上采样通常通过侧向连接辅助 [37]；在纯ViT骨干中，我们通过实验发现这是不必要的（第4节），简单的反卷积就足够了。我们假设这是因为ViT可以依赖于位置嵌入 [54] 来编码位置，也因为高维的ViT补丁嵌入不一定丢弃信息。 $ ^{4} $ 

我们将与两种也在纯骨干上构建的FPN变体进行比较（图2）。在第一种变体中，骨干被人为地划分为多个阶段以模仿分层骨干的阶段，并应用了侧向和自上而下的连接（图2（a） [16]）。第二种变体与第一种类似，但只使用最后一个图而不是划分的阶段（图2（b））。我们展示了这些FPN变体是不必要的（第4节）。 $ ^{5} $ 

骨干适应。对象检测器受益于高分辨率的输入图像，但在整个骨干中计算全局自注意力在内存上是禁止性的，并且速度慢。在这项研究中

[Warning: Content truncated due to length limit in this demo.]